{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71baea4",
   "metadata": {},
   "source": [
    "# Replicate project database from exported files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2d2d7",
   "metadata": {},
   "source": [
    "Use this notebook to set up a new brightway2 project on your computer, and load all the background and foreground databases, and project parameters, based on export files available online.\n",
    "\n",
    "**Warning:** Only works if there are no loops between the foreground databases. (see Section Fix inadequate project otherwise)\n",
    "\n",
    "**Warning:** If you import bw2packages, make sure you can trust the person who created the packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "201e9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw2 # version v2.3\n",
    "import eidl # https://github.com/haasad/EcoInventDownLoader\n",
    "import glob # https://docs.python.org/3/library/glob.html#glob.glob \n",
    "\n",
    "from bw2data.parameters import ActivityParameter, DatabaseParameter, ProjectParameter, Group\n",
    "import pandas as pd\n",
    "\n",
    "def ExportProjectParameters(f='ProjectParamExport.xlsx'):\n",
    "    params = { i:p.dict for i,p in enumerate(ProjectParameter.select() )}\n",
    "    pd.DataFrame.from_dict(params).to_excel(f)\n",
    "\n",
    "def LoadProjectParameters(f='ProjectParamExport.xlsx'):\n",
    "    df = pd.read_excel(f, index_col=0)\n",
    "    paramDict = df.to_dict(orient='dict')\n",
    "    paramList = [v for k,v in paramDict.items()]\n",
    "    bw2.parameters.new_project_parameters(paramList, overwrite=True)\n",
    "    bw2.parameters.recalculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff27442",
   "metadata": {},
   "source": [
    "## Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95af9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new project or set as current project\n",
    "project_name = 'cs_UppsalaNewCopy'\n",
    "if project_name not in bw2.projects:\n",
    "    bw2.projects.create_project(project_name)\n",
    "bw2.projects.set_current(project_name)\n",
    "\n",
    "if \"biosphere3\" not in bw2.databases:\n",
    "    bw2.bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10da69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ei_cutoff_36 already in the project.\n",
      "Database ei_apos_36 already in the project.\n",
      "Database ei_csq_36 already in the project.\n"
     ]
    }
   ],
   "source": [
    "# import the ecoinvent database (requires license)\n",
    "# and name it 'exactly' as stated in the documentation of the project your replicate\n",
    "# slow process: min 15 minutes for 3 versions of ecoinvent!\n",
    "\n",
    "ei_version = ['3.6', '3.6', '3.6']\n",
    "ei_systemmodel = ['cut-off', 'apos', 'consequential']\n",
    "ei_name = ['ei_cutoff_36', 'ei_apos_36', 'ei_csq_36']\n",
    "\n",
    "username= '' # you ecoinvent username\n",
    "password= '' # you ecoinvent password\n",
    "for n, eiv in enumerate(ei_version):\n",
    "    if ei_name[n] not in bw2.databases:\n",
    "        eidl.get_ecoinvent(db_name=ei_name[n], # db_name: name to give imported database (string) default is downloaded filename\n",
    "                           auto_write=True, # auto_write: automatically write database if no unlinked processes (boolean) default is False (i.e. prompt yes or no)\n",
    "                           download_path=None, # download_path: path to download .7z file to (string) default is download to temporary directory (.7z file is deleted after import)\n",
    "                           store_download=True, # store_download: store the .7z file for later reuse, default is True, only takes effect if no download_path is provided\n",
    "                           username=username, # username: ecoinvent username (string)\n",
    "                           password=password, # password: ecoivnent password (string)\n",
    "                           version = eiv, # version: ecoinvent version (string), eg '3.5'\n",
    "                           system_model=ei_systemmodel[n], # system_model: ecoinvent system model (string), one of {'cut-off', 'apos', 'consequential'}\n",
    "                          )\n",
    "    else:\n",
    "        print(\"Database {} already in the project.\".format(ei_name[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ccb2faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:51\n",
      "  Finished: 09/14/2021 16:40:51\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 77.80\n",
      "  Memory %: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:52\n",
      "  Finished: 09/14/2021 16:40:52\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 100.30\n",
      "  Memory %: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:52\n",
      "  Finished: 09/14/2021 16:40:53\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 72.70\n",
      "  Memory %: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [###########################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:53\n",
      "  Finished: 09/14/2021 16:40:53\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 75.60\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:53\n",
      "  Finished: 09/14/2021 16:40:54\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 87.50\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [###############] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:54\n",
      "  Finished: 09/14/2021 16:40:54\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 195.30\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:54\n",
      "  Finished: 09/14/2021 16:40:54\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 97.70\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "Writing activities to SQLite3 database:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:55\n",
      "  Finished: 09/14/2021 16:40:55\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 0.00\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:55\n",
      "  Finished: 09/14/2021 16:40:55\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 208.30\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:55\n",
      "  Finished: 09/14/2021 16:40:55\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 75.60\n",
      "  Memory %: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing activities to SQLite3 database:\n",
      "0% [##############] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Writing activities to SQLite3 database:\n",
      "  Started: 09/14/2021 16:40:56\n",
      "  Finished: 09/14/2021 16:40:56\n",
      "  Total time elapsed: 00:00:00\n",
      "  CPU %: 0.00\n",
      "  Memory %: 1.05\n"
     ]
    }
   ],
   "source": [
    "# using BW2Packages - ONLY IF YOU TRUST THE FILES as a someone with bad intensions could hide executable code in the bw2package files\n",
    "# import foreground databases and project parameters from files\n",
    "where_are_the_files = 'C://Users//eazzi//AppData//Local//pylca//Brightway3//cs_UppsalaDuplicate.c641eb45289d00b26a72112a023a35f9\\\\export\\\\'\n",
    "\n",
    "#import_order = [ 'background_system', 'material', 'material_tagged', 'pro_biochar', \n",
    "#                'use_1_tree-planting', 'use_2_green-roof', 'use_3_charcrete', 'use_4_filter', 'use_5_asphalt', \n",
    "#                'use_6_soil-private', 'use_7_benchmark', 'ranking']\n",
    "\n",
    "import_order = ['AllForegroundInOne']\n",
    "\n",
    "ordered_file_paths = []\n",
    "for db in import_order:\n",
    "    filesFound = glob.glob(where_are_the_files+db+'*.*', recursive=False) # returns a list\n",
    "    if len(filesFound):\n",
    "        ordered_file_paths.append(filesFound[0])\n",
    "    elif len(filesFound)==0:\n",
    "        raise Exception('Warning: no matching files for {} found in the folder. Verify import_order list and your folder content'.format(db))\n",
    "    else:\n",
    "        print('Warning: several matching files for {} found in the folder. Adding only first one'.format(db))\n",
    "        ordered_file_paths.append(filesFound[0])\n",
    "\n",
    "for fp in ordered_file_paths:\n",
    "    bw2.BW2Package.import_file(fp)\n",
    "    \n",
    "# add project parameters\n",
    "path_param = where_are_the_files+'ProjectParameters.xlsx'\n",
    "df = pd.read_excel(path_param, index_col=0)\n",
    "df = df.fillna('')\n",
    "paramDict = df.to_dict(orient='dict')\n",
    "paramList = [v for k,v in paramDict.items()]\n",
    "bw2.parameters.new_project_parameters(paramList, overwrite=True)\n",
    "\n",
    "for obj in Group.select().where(Group.fresh==False):\n",
    "    data = [\n",
    "        {'name':'FixParam',\n",
    "        'database':'pro_biochar',\n",
    "        'code':obj.name,\n",
    "        'amount':'1',\n",
    "        'formula':''}]\n",
    "    bw2.parameters.new_activity_parameters(data=data, \n",
    "                                           group=obj.name, \n",
    "                                           overwrite=True)\n",
    "bw2.parameters.recalculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea9efa",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10a745",
   "metadata": {},
   "source": [
    "### via bw2packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd3ceac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project is cs_UppsalaDuplicate\n",
      "background_system\n",
      "material\n",
      "material_tagged\n",
      "pro_biochar\n",
      "use_1_tree-planting\n",
      "use_2_green-roof\n",
      "use_3_charcrete\n",
      "use_4_filter\n",
      "use_5_asphalt\n",
      "use_6_soil-private\n",
      "use_7_benchmark\n",
      "ranking\n",
      "Exported files are in:\n",
      "C:\\Users\\eazzi\\AppData\\Local\\pylca\\Brightway3\\cs_UppsalaDuplicate.c641eb45289d00b26a72112a023a35f9\\export\n"
     ]
    }
   ],
   "source": [
    "name_of_bw_project = \"cs_UppsalaDuplicate\"\n",
    "bw2.projects.set_current(name_of_bw_project)\n",
    "print(\"Current project is {}\".format(bw2.projects.current))\n",
    "\n",
    "# THE ORDER IN THIS LIST IS IMPORTANT (e.g. ranking at the end, because depends on all other uses)\n",
    "objects_to_copy = [\n",
    "'background_system',\n",
    "'material',\n",
    "'material_tagged',\n",
    "'pro_biochar',\n",
    "'use_1_tree-planting',\n",
    "'use_2_green-roof',\n",
    "'use_3_charcrete',\n",
    "'use_4_filter',\n",
    "'use_5_asphalt',\n",
    "'use_6_soil-private',\n",
    "'use_7_benchmark',\n",
    "'ranking']\n",
    "\n",
    "bw2obj = []\n",
    "for o in objects_to_copy:\n",
    "    print(o)\n",
    "    #bw2.Database(o).process()\n",
    "    bw2obj.append(bw2.Database(o))\n",
    "\n",
    "pack_path = bw2.BW2Package.export_objs(objs=bw2obj, filename='AllForegroundInOne', folder='export')\n",
    "path_param = pack_path.rsplit('\\\\', 1)[0]+'\\\\ProjectParameters.xlsx'\n",
    "ExportProjectParameters(f=path_param)\n",
    "print('Exported files are in:')\n",
    "print(pack_path.rsplit('\\\\', 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7fd6d8",
   "metadata": {},
   "source": [
    "### Via Excel files or JSON-LD (to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8322f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_bw_project = \"cs_UppsalaDuplicate\"\n",
    "bw2.projects.set_current(name_of_bw_project)\n",
    "print(\"Current project is {}\".format(bw2.projects.current))\n",
    "\n",
    "# THE ORDER IN THIS LIST IS IMPORTANT (e.g. ranking at the end, because depends on all other uses)\n",
    "objects_to_copy = [\n",
    "'background_system',\n",
    "'material',\n",
    "'material_tagged',\n",
    "'pro_biochar',\n",
    "'use_1_tree-planting',\n",
    "'use_2_green-roof',\n",
    "'use_3_charcrete',\n",
    "'use_4_filter',\n",
    "'use_5_asphalt',\n",
    "'use_6_soil-private',\n",
    "'use_7_benchmark',\n",
    "'ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaa1f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://2.docs.brightway.dev/technical/bw2io.html?highlight=export#excel\n",
    "import bw2io\n",
    "bw2io.export.excel.write_lci_excel?\n",
    "# nested data would not be exported! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee68fd0",
   "metadata": {},
   "source": [
    "## Fix inadequate project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b040d",
   "metadata": {},
   "source": [
    "In case the project you want to copy has several interlinked databases, or if you want to merge some databases, or if you want to rename + relink a database, before you export your files for sharing: explore & adapt the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge 2 foregroundDatabases in one & relink them internally?\n",
    "name_of_bw_project = \"cs_UppsalaDuplicate\"\n",
    "bw2.projects.set_current(name_of_bw_project)\n",
    "print(\"Current project is {}\".format(bw2.projects.current))\n",
    "\n",
    "merge_in = 'background_system'\n",
    "to_merge = ['biomass', 'background-system', 'biomass_test']\n",
    "\n",
    "if merge_in not in bw2.databases:\n",
    "    bw2.Database(merge_in).register()\n",
    "\n",
    "# copy all activities in a merged database\n",
    "counter = 0\n",
    "for db in to_merge:\n",
    "    for a in bw2.Database(db):\n",
    "        if a not in bw2.Database(merge_in):\n",
    "            a.copy(code=a['code'], database=merge_in) # copies everything, including tags, comments, etc\n",
    "            counter+=1\n",
    "print(\"Copied {} activities to the new database '{}' \".format(counter, merge_in) )\n",
    "\n",
    "from bw2io.utils import DEFAULT_FIELDS, activity_hash\n",
    "\n",
    "# modify all the exchanges in the merged database, so they link to internal activities\n",
    "for old_db in to_merge:\n",
    "    print(\"Relinking for db {}\".format(old_db))\n",
    "    if old_db == merge_in:\n",
    "        print(\"No point relinking to same database.\")\n",
    "        break\n",
    "        \n",
    "    db = bw2.Database(merge_in)\n",
    "    other = bw2.Database(old_db)\n",
    "    assert db.backend == \"sqlite\", \"Relinking only allowed for SQLITE backends\"\n",
    "    assert other.backend == \"sqlite\", \"Relinking only allowed for SQLITE backends\"\n",
    "\n",
    "    # find dupplicates & candidates between old & new database\n",
    "    duplicates, candidates = {}, {}\n",
    "    altered = 0\n",
    "    for ds in db: # for activities in new database\n",
    "        # key = activity_hash(ds, DEFAULT_FIELDS) # creates a hash based on default field of activity # to avoid\n",
    "        key = ds.key[1] # because I have simply copied them, and they may have _copy1 extensions\n",
    "        if key in candidates: # candidates is empty at first\n",
    "            duplicates.setdefault(key, []).append(ds)\n",
    "        else:\n",
    "            candidates[key] = ds.key # key is just a hash, ds.key is (code, hash)\n",
    "            \n",
    "    # traverse all the activities and their technosphere/biosphere exchanges, for changing the exchanges\n",
    "    for i, exc in enumerate(\n",
    "                        exc for act in db for exc in act.exchanges()\n",
    "                        if exc.get(\"type\") in {\"biosphere\", \"technosphere\"} and exc.input[0] == old_db\n",
    "                ):\n",
    "                    # Use the input activity to generate the hash.\n",
    "                    key = exc.input.key[1] #activity_hash(exc.input, DEFAULT_FIELDS)\n",
    "                    if key in duplicates:\n",
    "                        raise StrategyError(format_nonunique_key_error(exc.input, DEFAULT_FIELDS, duplicates[key]))\n",
    "                    elif key in candidates:\n",
    "                        exc[\"input\"] = candidates[key]\n",
    "                        altered += 1\n",
    "                    exc.save()\n",
    "    print('-- {} exchanges were modified'.format(altered))\n",
    "    \n",
    "    db.process()\n",
    "    print(\n",
    "        \"Relinked database '{}', {} exchange inputs changed from '{}' to '{}'.\".format(\n",
    "            db.name, altered, other.name, db.name\n",
    "        )\n",
    "    )\n",
    "\n",
    "other_fgdb = [\n",
    "'material',\n",
    "'material_tagged',\n",
    "'pro_biochar',\n",
    "'ranking',\n",
    "'use_1_tree-planting',\n",
    "'use_2_green-roof',\n",
    "'use_3_charcrete',\n",
    "'use_4_filter',\n",
    "'use_5_asphalt',\n",
    "'use_6_soil private',\n",
    "'use_7_benchmark']\n",
    "\n",
    "for fg_db in other_fgdb:\n",
    "    fg_db = bw2.Database(fg_db) # the db to relink\n",
    "    new_db = bw2.Database(merge_in) # new db\n",
    "    \n",
    "    for old_db in to_merge:\n",
    "        old_db = bw2.Database(old_db) # old db\n",
    "\n",
    "        # find dupplicates & candidates between old & new database\n",
    "        duplicates, candidates = {}, {}\n",
    "        altered = 0\n",
    "        for ds in new_db: # for activities in new database\n",
    "            # key = activity_hash(ds, DEFAULT_FIELDS) # creates a hash based on default field of activity # to avoid\n",
    "            key = ds.key[1] # because I have simply copied them, and they may have _copy1 extensions\n",
    "            if key in candidates: # candidates is empty at first\n",
    "                duplicates.setdefault(key, []).append(ds)\n",
    "            else:\n",
    "                candidates[key] = ds.key # key is just a hash, ds.key is (code, hash)\n",
    "\n",
    "        # traverse all the activities and their technosphere/biosphere exchanges, for changing the exchanges\n",
    "        for i, exc in enumerate(\n",
    "                            exc for act in fg_db for exc in act.exchanges()\n",
    "                            if exc.get(\"type\") in {\"biosphere\", \"technosphere\"} and exc.input[0] == old_db.name\n",
    "                    ):\n",
    "                        # Use the input activity to generate the hash.\n",
    "                        key = exc.input.key[1] \n",
    "                        if key in duplicates:\n",
    "                            raise StrategyError(format_nonunique_key_error(exc.input, DEFAULT_FIELDS, duplicates[key]))\n",
    "                        elif key in candidates:\n",
    "                            exc[\"input\"] = candidates[key]\n",
    "                            altered += 1\n",
    "                        exc.save()\n",
    "\n",
    "        fg_db.process()\n",
    "        print(\n",
    "            \"Relinked database '{}', {} exchange inputs changed from '{}' to '{}'.\".format(\n",
    "                fg_db.name, altered, old_db.name, new_db.name\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to rename a database, to remove a ' ' space in its name\n",
    "# Trick: don't use rename, gonna mess up the things\n",
    "# Instead: merge one into one other + relink all others, then delete old one\n",
    "\n",
    "name_of_bw_project = \"cs_UppsalaDuplicate\"\n",
    "bw2.projects.set_current(name_of_bw_project)\n",
    "print(\"Current project is {}\".format(bw2.projects.current))\n",
    "\n",
    "\n",
    "merge_in = 'use_6_soil-private'\n",
    "to_merge = ['use_6_soil private']\n",
    "\n",
    "if merge_in not in bw2.databases:\n",
    "    bw2.Database(merge_in).register()\n",
    "\n",
    "# copy all activities in a merged database\n",
    "counter = 0\n",
    "for db in to_merge:\n",
    "    for a in bw2.Database(db):\n",
    "        if a not in bw2.Database(merge_in):\n",
    "            a.copy(code=a['code'], database=merge_in) # copies everything, including tags, comments, etc\n",
    "            counter+=1\n",
    "print(\"Copied {} activities to the new database '{}' \".format(counter, merge_in) )\n",
    "\n",
    "# modify all the exchanges in the merged database, so they link to internal activities\n",
    "for old_db in to_merge:\n",
    "    print(\"Relinking for db {}\".format(old_db))\n",
    "    if old_db == merge_in:\n",
    "        print(\"No point relinking to same database.\")\n",
    "        break\n",
    "        \n",
    "    db = bw2.Database(merge_in)\n",
    "    other = bw2.Database(old_db)\n",
    "    assert db.backend == \"sqlite\", \"Relinking only allowed for SQLITE backends\"\n",
    "    assert other.backend == \"sqlite\", \"Relinking only allowed for SQLITE backends\"\n",
    "\n",
    "    # find dupplicates & candidates between old & new database\n",
    "    duplicates, candidates = {}, {}\n",
    "    altered = 0\n",
    "    for ds in db: # for activities in new database\n",
    "        # key = activity_hash(ds, DEFAULT_FIELDS) # creates a hash based on default field of activity # to avoid\n",
    "        key = ds.key[1] # because I have simply copied them, and they may have _copy1 extensions\n",
    "        if key in candidates: # candidates is empty at first\n",
    "            duplicates.setdefault(key, []).append(ds)\n",
    "        else:\n",
    "            candidates[key] = ds.key # key is just a hash, ds.key is (code, hash)\n",
    "            \n",
    "    # traverse all the activities and their technosphere/biosphere exchanges, for changing the exchanges\n",
    "    for i, exc in enumerate(\n",
    "                        exc for act in db for exc in act.exchanges()\n",
    "                        if exc.get(\"type\") in {\"biosphere\", \"technosphere\"} and exc.input[0] == old_db\n",
    "                ):\n",
    "                    # Use the input activity to generate the hash.\n",
    "                    key = exc.input.key[1] #activity_hash(exc.input, DEFAULT_FIELDS)\n",
    "                    if key in duplicates:\n",
    "                        raise StrategyError(format_nonunique_key_error(exc.input, DEFAULT_FIELDS, duplicates[key]))\n",
    "                    elif key in candidates:\n",
    "                        exc[\"input\"] = candidates[key]\n",
    "                        altered += 1\n",
    "                    exc.save()\n",
    "    print('-- {} exchanges were modified'.format(altered))\n",
    "    \n",
    "    db.process()\n",
    "    print(\n",
    "        \"Relinked database '{}', {} exchange inputs changed from '{}' to '{}'.\".format(\n",
    "            db.name, altered, other.name, db.name\n",
    "        )\n",
    "    )\n",
    "\n",
    "other_fgdb = [\n",
    "'material',\n",
    "'material_tagged',\n",
    "'pro_biochar',\n",
    "'ranking',\n",
    "'use_1_tree-planting',\n",
    "'use_2_green-roof',\n",
    "'use_3_charcrete',\n",
    "'use_4_filter',\n",
    "'use_5_asphalt',\n",
    "'use_6_soil private',\n",
    "'use_7_benchmark']\n",
    "\n",
    "for fg_db in other_fgdb:\n",
    "    fg_db = bw2.Database(fg_db) # the db to relink\n",
    "    new_db = bw2.Database(merge_in) # new db\n",
    "    \n",
    "    for old_db in to_merge:\n",
    "        old_db = bw2.Database(old_db) # old db\n",
    "\n",
    "        # find dupplicates & candidates between old & new database\n",
    "        duplicates, candidates = {}, {}\n",
    "        altered = 0\n",
    "        for ds in new_db: # for activities in new database\n",
    "            # key = activity_hash(ds, DEFAULT_FIELDS) # creates a hash based on default field of activity # to avoid\n",
    "            key = ds.key[1] # because I have simply copied them, and they may have _copy1 extensions\n",
    "            if key in candidates: # candidates is empty at first\n",
    "                duplicates.setdefault(key, []).append(ds)\n",
    "            else:\n",
    "                candidates[key] = ds.key # key is just a hash, ds.key is (code, hash)\n",
    "\n",
    "        # traverse all the activities and their technosphere/biosphere exchanges, for changing the exchanges\n",
    "        for i, exc in enumerate(\n",
    "                            exc for act in fg_db for exc in act.exchanges()\n",
    "                            if exc.get(\"type\") in {\"biosphere\", \"technosphere\"} and exc.input[0] == old_db.name\n",
    "                    ):\n",
    "                        # Use the input activity to generate the hash.\n",
    "                        key = exc.input.key[1] \n",
    "                        if key in duplicates:\n",
    "                            raise StrategyError(format_nonunique_key_error(exc.input, DEFAULT_FIELDS, duplicates[key]))\n",
    "                        elif key in candidates:\n",
    "                            exc[\"input\"] = candidates[key]\n",
    "                            altered += 1\n",
    "                        exc.save()\n",
    "\n",
    "        fg_db.process()\n",
    "        print(\n",
    "            \"Relinked database '{}', {} exchange inputs changed from '{}' to '{}'.\".format(\n",
    "                fg_db.name, altered, old_db.name, new_db.name\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
